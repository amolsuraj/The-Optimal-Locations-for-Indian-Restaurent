{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Optimal Locations for Indian Restaurent\n",
    "\n",
    "## Applied Data Science Capstone by IBM/Coursera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* [Introducation to Bussiness problem](#introducation)\n",
    "* [Data]()\n",
    "* [Methodology]()\n",
    "* [Result]()\n",
    "* [Conclusion](#clonclustion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducation to Bussiness problem<a name=\"introduction\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an Indian and food lover, I was always curious to, what if someone like me want to open Indian restaurant. Great!!! \n",
    "I choose London for my analysis. London is diverse city. London is home of 500k people roughly 10% of total population, originated from Indian, Pakistan and Bangladesh. India Pakistan and Bangladesh were a single country in colonial era. And it had been ruled by Britain, so lot of people for Indian subcontinent are moved to Britain and especially London, Additional to that, lot of travellers visit to London. Thant’s why I am so excited about London\n",
    "\n",
    "Since we have decided to open an Indian restaurant in London, we need to get optimal location. For that we are considering some criteria. \n",
    "•\tWe will consider the area which has more Indian population\n",
    "•\tRestaurant should be not crowed with another Indian restaurants\n",
    "•\tIt should be as near to city centre as possible\n",
    "There are 33 boroughs in London, and we will study each of them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.2.0-py3-none-any.whl (118 kB)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Downloading geographiclib-1.52-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-1.52 geopy-2.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -andas (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install geopy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geocoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2892/3801861304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m  \u001b[0mgeopy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeocoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfolium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geocoder'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "import pandas.io.json\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from  geopy import distance\n",
    "\n",
    "import geocoder\n",
    "import folium\n",
    "\n",
    "# Hide all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('Libraries Imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data\n",
    "   We will work in Borough of London, UK, we will scrap the data from [List of London Borough](https://en.wikipedia.org/wiki/List_of_London_boroughs). Page contens two table 'List of boroughs and local authorities' and\n",
    "   'City of London'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html('https://en.wikipedia.org/wiki/List_of_London_boroughs',header=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_html('https://en.wikipedia.org/wiki/List_of_London_boroughs',header=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.append(df2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Population (2013 est)[1]'][32] = df['Population(2011 est)'][32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Plot the Borough on Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to get coordinates\n",
    "def get_latlng1(neighborhood):\n",
    "    # initialize your variable to None\n",
    "    lat_lng_coords = None\n",
    "    # loop until you get the coordinates\n",
    "    while(lat_lng_coords is None):\n",
    "        g = geocoder.arcgis('{}, London,UK '.format(neighborhood))\n",
    "        lat_lng_coords = g.latlng\n",
    "    return lat_lng_coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a Indian population, I will take down the population manually from wikipedia page of every borough, Because it was little bit harder for me to scrab.\n",
    "I will consider Indian, Pakistani, and Bangladeshi as Indian pople as the food is simillar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indian_population = [23144, 35479,8554,74147,8494,20074,38095,64737,19841, 12543,15684,6119, 12282,72226, 8046,48634,64026,9147,4324,10226,\n",
    "10276,7584,17659, 110053, 92722, 7722, 11354, 10232, 90606, 40113, 19853, 15840, 464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = False\n",
    "try:\n",
    "    London_df = pd.read_csv('London_df.csv')\n",
    "    loaded = True\n",
    "except:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not loaded:  \n",
    "    #first we need to get the co-ordinated of London,UK\n",
    "    g = geocoder.arcgis( 'London, UK ')\n",
    "    coordinated_centerlondon = g.latlng\n",
    "\n",
    "    coords_london = [ get_latlng1(neighborhood) for neighborhood in df[\"Borough\"].tolist() ]\n",
    "    df['LatLng'] = coords_london\n",
    "    df['Lat'] = df['LatLng'].apply(lambda x:x[0])\n",
    "    df['Lng'] = df['LatLng'].apply(lambda x:x[1])\n",
    "    London_df = df[['Borough','Lat','Lng','Area (sq mi)','Population (2013 est)[1]']]\n",
    "    London_df.columns = ['Borough','Lat','Lng','Area','Population']\n",
    "    London_df.Borough = London_df['Borough'].apply(lambda x:x.split('[')[0])\n",
    "    \n",
    "    #adding Indian population to Data frames\n",
    "    London_df['Indian_population'] = indian_population    \n",
    "    \n",
    "    London_df['Dist_from_center'] = np.NaN\n",
    "    for index in range(London_df.shape[0]):\n",
    "        coords_1 = coordinated_centerlondon\n",
    "        coords_2 = (London_df['Lat'].iloc[index],London_df['Lng'].iloc[index])\n",
    "        \n",
    "        # get the of borough from center of the london city\n",
    "        London_df['Dist_from_center'].iloc[index] = distance.distance(coords_1, coords_2).km\n",
    "    London_df.to_csv(r'C:\\Users\\Shrirang\\Desktop\\Python Practice\\Online Courses\\IMB Data Science Cousre\\Capstone_Project\\Coursera_Capstone\\Capstone_project\\London_df.csv',index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the center location of London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = geocoder.arcgis(' London,UK ')\n",
    "coordinated_centerlondon = g.latlng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinated_centerlondon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create map of London and superinpose the Neighborhood on it\n",
    "map_la = folium.Map(location = coordinated_centerlondon, zoom_start = 10)\n",
    "folium.Marker(coordinated_centerlondon, popup='London_center').add_to(map_la)\n",
    "for lat, lng in zip(London_df['Lat'], London_df['Lng']):\n",
    "    #folium.CircleMarker([lat, lng], radius=2, color='blue', fill=True, fill_color='blue', fill_opacity=1).add_to(map_la)\n",
    "    folium.Circle([lat,lng], radius=30,color =\"blue\").add_to(map_la)\n",
    "map_la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Data from Foursquere API\n",
    "\n",
    "Foursquare API is excelent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foruesqure credentials\n",
    "client_id = 'XXX'\n",
    "client_secret = 'XXX'\n",
    "version = '20200724'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this id's are aquired from Foursqure\n",
    "food_category = '4d4b7105d754a06374d81259'\n",
    "indian_Restaurant =     ['4bf58dd8d48988d10f941735','54135bf5e4b08f3d2429dfe5','54135bf5e4b08f3d2429dff3',\n",
    "                         '54135bf5e4b08f3d2429dff5','54135bf5e4b08f3d2429dfe2','54135bf5e4b08f3d2429dff2',\n",
    "                         '54135bf5e4b08f3d2429dfe1','54135bf5e4b08f3d2429dfe3','54135bf5e4b08f3d2429dfe8',\n",
    "                         '54135bf5e4b08f3d2429dfe9','54135bf5e4b08f3d2429dfe6','54135bf5e4b08f3d2429dfdf',\n",
    "                         '54135bf5e4b08f3d2429dfe4','54135bf5e4b08f3d2429dfe7','54135bf5e4b08f3d2429dfea',\n",
    "                         '54135bf5e4b08f3d2429dfeb','54135bf5e4b08f3d2429dfed','54135bf5e4b08f3d2429dfee',\n",
    "                         '54135bf5e4b08f3d2429dff4','54135bf5e4b08f3d2429dfe0','54135bf5e4b08f3d2429dfdd',\n",
    "                         '54135bf5e4b08f3d2429dff6','54135bf5e4b08f3d2429dfef','54135bf5e4b08f3d2429dff0',\n",
    "                         '54135bf5e4b08f3d2429dff1','54135bf5e4b08f3d2429dfde','54135bf5e4b08f3d2429dfec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 2000\n",
    "limit = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the number of Indian restaurants around the Neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = False\n",
    "try:\n",
    "    venues_df = pd.read_csv('venues_df.csv')\n",
    "    csv = True\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not csv:\n",
    "    venues = []\n",
    "    for lat, lng, borough in zip(London_df['Lat'], London_df['Lng'],London_df['Borough']):\n",
    "        for i in indian_Restaurant:\n",
    "            url = 'https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&categoryId={}&radius={}&limit={}'.format(\n",
    "                        client_id, client_secret, version, lat,lng ,i, radius, limit)\n",
    "            result = requests.get(url).json()\n",
    "\n",
    "            for venue in result['response']['groups'][0]['items']:\n",
    "                venues.append((borough,lat,lng,\n",
    "                                      venue['venue']['name'],\n",
    "                                      venue['venue']['categories'][0]['name'],\n",
    "                                      venue['venue']['location']['lat'],\n",
    "                                      venue['venue']['location']['lng'],\n",
    "                                      venue['venue']['location']['distance']))\n",
    "    venues_df = pd.DataFrame(venues,columns=['Borough','lat','lng','name','categori','venue_lat','vanue_lng','distance'])\n",
    "    venues_df.to_csv(r'C:\\Users\\Shrirang\\Desktop\\Python Practice\\Online Courses\\IMB Data Science Cousre\\Capstone_Project\\Coursera_Capstone\\Capstone_project\\venues_df.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venues_df = venues_df.merge(London_df[['Borough','Area','Population']],on = 'Borough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "venues_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get the number of the restaurants per sq.mil of area, \n",
    "London_df['Indian_rest_count'] = venues_df.groupby('Borough').count().reset_index()['lat']\n",
    "\n",
    "#London_df['rest_per_area'] = London_df['Area']/London_df['Indian_rest_count']\n",
    "#London_df['rest_per_people'] = London_df['Population']/London_df['Indian_rest_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average Area of borough is                           {:.2f} sq mi'.format(London_df[\"Area\"].mean()))\n",
    "print('Average Population per borough is                    {:.2f} '.format(London_df[\"Population\"].mean()))\n",
    "print('Average Indian population per borough is             {:.2f} '.format(London_df[\"Indian_population\"].mean()))\n",
    "print('Average distance of the borough from city center is  {:.2f} km '.format(London_df[\"Dist_from_center\"].mean()))\n",
    "print('Average restaurants per borough is                   {:.2f} '.format(London_df[\"Indian_rest_count\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in ['Area','Population','Indian_population','Dist_from_center','Indian_rest_count']:\n",
    "    fig = plt.figure(figsize=(16,11))\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.barh(London_df['Borough'],London_df[i], alpha= 0.9)\n",
    "    ax.set_ylabel('Borough',fontsize=18)\n",
    "    ax.set_xlabel(i,fontsize=18)\n",
    "\n",
    "    #for tick in ax.get_xticklabels():\n",
    "        #tick.set_rotation(90)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[[\"Indian_population\",\"Indian_rest_count\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the top 100 venues from neighborhood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100 = False\n",
    "try:\n",
    "    top_100_df = pd.read_csv(\"top_100.csv\")\n",
    "    top_100 = True\n",
    "except:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not top_100:\n",
    "    top_100 = []\n",
    "    for borough,lat, lng in zip(London_df['Borough'],London_df['Lat'], London_df['Lng']):\n",
    "\n",
    "        # create the API request URL\n",
    "        url = \"https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}\".format(\n",
    "            client_id,\n",
    "            client_secret,\n",
    "            version,\n",
    "            lat,\n",
    "            lng,\n",
    "            2000, \n",
    "            100)\n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n",
    "\n",
    "        # return only relevant information for each nearby venue\n",
    "        for top in results:\n",
    "            top_100.append((\n",
    "                borough,\n",
    "                lat, \n",
    "                lng, \n",
    "                top['venue']['name'], \n",
    "                top['venue']['location']['lat'], \n",
    "                top['venue']['location']['lng'],  \n",
    "                top['venue']['categories'][0]['name']))\n",
    "    top_100_df = pd.DataFrame(data = top_100, columns=['Borough','Lat','Lng','name','lat','lng','category'])\n",
    "    top_100_df.to_csv(r'C:\\Users\\Shrirang\\Desktop\\Python Practice\\Online Courses\\IMB Data Science Cousre\\Capstone_Project\\Coursera_Capstone\\Capstone_project\\top_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_100_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Methodology\n",
    "\n",
    "We will use area population and venues to divide the Boroughs. We will make clusters of boroughs which has same qualities. For that we will use unsupervised machine learning algorithm K-mean clustering. Also, we will use Elbow method and Sillihoette score to get K values. After getting we will narrow down our analysis to select the Borough which has high Indian origin population, low number of Indian restaurants and it should be as possible as close to city centre. With these criteria we will find the location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_df[['Borough','category']].groupby('Borough').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 282 unique categories present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} unique categories present in Borough'.format(len(top_100_df['category'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy = pd.get_dummies(top_100_df[['category']],prefix=\"\", prefix_sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add borough column to top_100_dummy\n",
    "top_100_dummy['Borough'] = top_100_df['Borough']\n",
    "\n",
    "#rearrange the column\n",
    "column = top_100_dummy.columns.tolist()\n",
    "\n",
    "#rearrange the column\n",
    "column = top_100_dummy.columns.tolist()\n",
    "\n",
    "top_100_dummy = top_100_dummy[column[-1:] + column[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_100_dummy_grouped = top_100_dummy.groupby('Borough').mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top 10 commom place from each of the borough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_venues = 10\n",
    "\n",
    "indicators = ['st', 'nd', 'rd']\n",
    "\n",
    "# create columns according to number of top venues\n",
    "areaColumns = ['Borough']\n",
    "freqColumns = []\n",
    "for ind in np.arange(num_top_venues):\n",
    "    try:\n",
    "        freqColumns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n",
    "    except:\n",
    "        freqColumns.append('{}th Most Common Venue'.format(ind+1))\n",
    "columns = areaColumns+freqColumns\n",
    "\n",
    "# create a new dataframe\n",
    "borough_venues_sorted = pd.DataFrame(columns=columns)\n",
    "borough_venues_sorted['Borough'] = top_100_dummy_grouped ['Borough']\n",
    "\n",
    "\n",
    "for ind in np.arange(top_100_dummy_grouped.shape[0]):\n",
    "    row_categories = top_100_dummy_grouped.iloc[ind, :].iloc[1:]\n",
    "    row_categories_sorted = row_categories.sort_values(ascending=False)\n",
    "    borough_venues_sorted.iloc[ind, 1:] = row_categories_sorted.index.values[0:num_top_venues]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borough_venues_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets add the popuation, area, and distance from center to make a clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped['Area'] = London_df['Area']\n",
    "top_100_dummy_grouped['Population'] = London_df['Population']\n",
    "top_100_dummy_grouped['Dist_from_center'] = London_df['Dist_from_center']\n",
    "top_100_dummy_grouped['Indian_population'] = London_df['Indian_population']\n",
    "top_100_dummy_grouped['Indian_rest_count'] = London_df['Indian_rest_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets re arrange the columns of data set\n",
    "\n",
    "column = top_100_dummy_grouped.columns.tolist()\n",
    "columns_new = column[:1] + column[-5:] + column[1:-5]\n",
    "top_100_dummy_grouped = top_100_dummy_grouped[columns_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped_scaled = RobustScaler().fit_transform(top_100_dummy_grouped.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped_scaled = pd.DataFrame(data = top_100_dummy_grouped_scaled, \n",
    "                                            columns=top_100_dummy_grouped.columns.tolist()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_100_dummy_grouped_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples,silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intertias = {}\n",
    "silhouette_scores= {}\n",
    "klist = range(2,15)\n",
    "for k in klist:\n",
    "    kmeans = KMeans(n_clusters= k ,init='k-means++' , n_init=10).fit(top_100_dummy_grouped_scaled.iloc[:,:5])\n",
    "    label = kmeans.predict(top_100_dummy_grouped_scaled.iloc[:,:5])\n",
    "    intertias[k] = kmeans.inertia_\n",
    "    silhouette_scores[k] = silhouette_score(X = top_100_dummy_grouped_scaled.iloc[:,:5],labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(klist, intertias.values(), 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(klist, silhouette_scores.values(), 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Silhouette score for k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see k=4 gives good silhouette score , we will use this for our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters= 4 ,init='k-means++' , n_init=10).fit(top_100_dummy_grouped_scaled.iloc[:,:5])\n",
    "label = kmeans.predict(top_100_dummy_grouped_scaled.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df['cluster_labels'] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map of boroughes with clusters_labes  \n",
    "map_clusters = folium.Map(location= coordinated_centerlondon, zoom_start=11)\n",
    "\n",
    "# set color scheme for the clusters\n",
    "x = np.arange(4)\n",
    "ys = [i+x+(i*x)**2 for i in range(4)]\n",
    "colors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\n",
    "rainbow = [colors.rgb2hex(i) for i in colors_array]\n",
    "\n",
    "# add markers to the map\n",
    "markers_colors = []\n",
    "for lat, lng, borough, cluster in zip(London_df['Lat'], London_df['Lng'], London_df['Borough'], London_df['cluster_labels']):\n",
    "    label = folium.Popup(str(borough) + ' - Cluster ' + str(cluster), parse_html=True)\n",
    "    folium.CircleMarker(\n",
    "        [lat, lng],\n",
    "        radius=2.5,\n",
    "        popup=label,\n",
    "        color=rainbow[cluster-1],\n",
    "        fill=True,\n",
    "        fill_color=rainbow[cluster-1],\n",
    "        fill_opacity=0.7).add_to(map_clusters)\n",
    "       \n",
    "map_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[London_df['cluster_labels'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[London_df['cluster_labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[London_df['cluster_labels'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[London_df['cluster_labels'] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "London_df[London_df['Borough'] == 'Redbridge']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 3 has more number of the Indian population , compaired with other clusters, but has low number of the Indian restaurants unlike cluster 1,\n",
    "Redbridge is looking very good for opening new retaurants because , it has very high numbers of Indian population(3 times than average), also it's with in 5 km from city center , More importantly it has only one Indian restaurant.\n",
    "Lets explore more the Redbridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redbridge = top_100_df[top_100_df['Borough'] == 'Redbridge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redbridge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "redbridge_rest = redbridge[redbridge['category'].str.lower().str.contains('restaurant')].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redbridge_rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result\n",
    "Cluster number 3 seems to be more interesting. It has more Indian population and has low number of Indian restaurants Unlike the other cluster, if we narrow down our analysis, we can see that Redbridge has Indian population around 32% of the total population. Redbridge has 27 restaurants in that only one is Indian. Additional to that it is very close to city centre around 4.6 Km. That is why Redbridge is very promising area to open the new Indian restaurant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_la = folium.Map(location = (51.475773,-0.080698), zoom_start = 13)\n",
    "folium.Marker((51.475773,-0.080698), popup='Redbridge').add_to(map_la)\n",
    "for lat, lng in zip(redbridge_rest['lat'], redbridge_rest['lng']):\n",
    "    #folium.CircleMarker([lat, lng], radius=2, color='blue', fill=True, fill_color='blue', fill_opacity=1).add_to(map_la)\n",
    "    folium.Circle([lat,lng], radius=3,color =\"blue\").add_to(map_la)\n",
    "map_la"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Conclusion <a name=\"conclusion\"></a>\n",
    "\n",
    "London has good number Indian, Pakistani and Bangladeshi people. It is good to open an Indian restaurant in anywhere in London however, the location of the restaurant is key point in business. So, we consider some criteria to open the Indian restaurant.\n",
    "And according to our analysis, Redbridge borough is very good place to open the new Indian restaurant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
